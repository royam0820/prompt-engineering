{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royam0820/prompt-engineering/blob/main/l2_guidelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ebe2e9d-685d-4ea3-ab7c-9589caaabff5",
      "metadata": {
        "id": "7ebe2e9d-685d-4ea3-ab7c-9589caaabff5"
      },
      "source": [
        "# Principal Guidelines for Prompting\n",
        "In this lesson, you'll practice two prompting principles and their related tactics in order to write effective prompts for large language models.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the main guidelines for creating effective prompts, explained in French:\n",
        "\n",
        "1. **Be specific**: The more specific your prompt, the more relevant the AI ​​response will be.\n",
        "\n",
        "2. **Provide context**: Provide basic information to help the AI ​​understand the situation.\n",
        "\n",
        "3. **Use clear language**: Avoid ambiguity and complex sentences.\n",
        "\n",
        "4. **Structure your requests**: Organize your questions or instructions logically.\n",
        "\n",
        "5. **Set the desired response format**: Indicate whether you want a list, paragraph, etc.\n",
        "\n",
        "6. **Include examples**: If possible, provide examples of expected responses.\n",
        "\n",
        "7. **Specify the tone and style**: Specify whether you want a formal, friendly, technical, etc. response.\n",
        "\n",
        "8. **Use role instructions**: Ask the AI ​​to adopt a specific role if necessary.\n",
        "\n",
        "9. **Ask follow-up questions**: Break complex tasks into several steps.\n",
        "\n",
        "10. **Iterate and refine**: Don’t hesitate to adjust your prompts based on the results you get.\n",
        "\n",
        "By following these guidelines, you can significantly improve the quality and relevance of AI-generated responses."
      ],
      "metadata": {
        "id": "24ZbpgDpZRwp"
      },
      "id": "24ZbpgDpZRwp"
    },
    {
      "cell_type": "markdown",
      "id": "00bab499-9a50-4bd0-a622-1c914c6ccc29",
      "metadata": {
        "id": "00bab499-9a50-4bd0-a622-1c914c6ccc29"
      },
      "source": [
        "For this lesson, we are using the OPENAI api key.\n",
        "To get it, here is the [url](https://platform.openai.com/api-keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "loading libraries and openai api key."
      ],
      "metadata": {
        "id": "po9bboxg2MS6"
      },
      "id": "po9bboxg2MS6"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ued_418AogZz",
        "outputId": "4cb157be-58b7-46d8-857c-90ccba69c161"
      },
      "id": "Ued_418AogZz",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "m39DjFvJoI0H"
      },
      "id": "m39DjFvJoI0H",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n"
      ],
      "metadata": {
        "id": "fP8gQ5gRaZby"
      },
      "id": "fP8gQ5gRaZby",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dswy5j-noziQ",
        "outputId": "ef893c5d-5cf1-4536-f645-02fa17b83678"
      },
      "id": "dswy5j-noziQ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.35.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8b32ac4",
      "metadata": {
        "id": "e8b32ac4"
      },
      "source": [
        "NB:  we will be this openai version for the whole course sessions on prompt engineering.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "JzhXT5sAnTLA"
      },
      "id": "JzhXT5sAnTLA",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a3acefa8-f8f1-4ef8-932e-9bcefa142666",
      "metadata": {
        "id": "a3acefa8-f8f1-4ef8-932e-9bcefa142666"
      },
      "source": [
        "#### helper function\n",
        "Throughout this course, we will use OpenAI's `gpt-3.5-turbo` model and the [chat completions endpoint](https://platform.openai.com/docs/guides/chat).\n",
        "\n",
        "This helper function will make it easier to use prompts and look at the generated outputs.  \n",
        "**Note**: In June 2023, OpenAI updated gpt-3.5-turbo. The results you see in the notebook may be slightly different than those in the video. Some of the prompts have also been slightly modified to product the desired results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7dff174",
      "metadata": {
        "height": 149,
        "tags": [],
        "id": "a7dff174"
      },
      "outputs": [],
      "source": [
        "# older openai version == 0.27.0\n",
        "# def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "#     messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "#     response = openai.ChatCompletion.create(\n",
        "#         model=model,\n",
        "#         messages=messages,\n",
        "#         temperature=0, # this is the degree of randomness of the model's output\n",
        "#     )\n",
        "#     return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the helper function\n",
        "\n",
        "# initializing the OpenAI client\n",
        "client = openai.OpenAI()\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "47w3YM77pZG6"
      },
      "id": "47w3YM77pZG6",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: `messages = [{\"role\": \"user\", \"content\": prompt}]` Each message is a dictionary with \"role\" and \"content\" keys. Here, it's setting up a single message with the role \"user\" and the content being the provided prompt."
      ],
      "metadata": {
        "id": "utetm6fRqX-O"
      },
      "id": "utetm6fRqX-O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting Delimiters"
      ],
      "metadata": {
        "id": "CDSIjBWsr6OJ"
      },
      "id": "CDSIjBWsr6OJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Triple Quotes\n",
        "Useful for defining long strings or multiline inputs.\n",
        "\n",
        "\n",
        "```\n",
        "prompt = \"\"\"\n",
        "This is an example of using triple quotes.\n",
        "\"\"\"\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "NoDtAXL5sExl"
      },
      "id": "NoDtAXL5sExl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Triple Backticks\n",
        "Often used to denote code blocks or formatted text.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "prompt = '''\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "HgMbXnIqsT5F"
      },
      "id": "HgMbXnIqsT5F"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Brackets\n",
        "Curly braces {}, square brackets [], or angle brackets <> can be used to enclose specific parts of the prompt.\n",
        "\n",
        "\n",
        "```\n",
        "prompt = \"This is an example of using {curly braces}.\"\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "VDO9Xzy8s5Og"
      },
      "id": "VDO9Xzy8s5Og"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parentheses\n",
        "To encapsulate specific elements.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "prompt = \"Please (enter your response here).\"\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "KsFcG8mWtNh4"
      },
      "id": "KsFcG8mWtNh4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dashes or Hyphens\n",
        "To separate sections or emphasize certain parts.\n",
        "\n",
        "\n",
        "```\n",
        "prompt = \"Introduction: --- Body: --- Conclusion: ---\"\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "cUt3hdsktbqI"
      },
      "id": "cUt3hdsktbqI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Colons and Semicolons\n",
        "To introduce lists or separate statements.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "prompt = \"Items: Apple, Banana, Cherry;\"\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "BLtoSNlGtoXk"
      },
      "id": "BLtoSNlGtoXk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Asterisks or Stars\n",
        "For bullet points or emphasis.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "prompt = \"* This is a bullet point.\"\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dYlZ4vqUt0cp"
      },
      "id": "dYlZ4vqUt0cp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipes\n",
        "Vertical bars can be used for list-like structures.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "prompt = \"Option 1 | Option 2 | Option 3\"\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "FENmM8eZuId0"
      },
      "id": "FENmM8eZuId0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Slashes\n",
        "To separate alternatives or paths.\n",
        "\n",
        "\n",
        "```\n",
        "prompt = \"Choose one: option1/option2/option3\"\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "4-vPpTsFuVRO"
      },
      "id": "4-vPpTsFuVRO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arrows\n",
        "To indicate directions or flows.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "prompt = \"Start -> Step 1 -> Step 2 -> End\"\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "4QBE9vZeuiZg"
      },
      "id": "4QBE9vZeuiZg"
    },
    {
      "cell_type": "markdown",
      "id": "3b62298e-2181-4e73-bb40-77e20c655231",
      "metadata": {
        "id": "3b62298e-2181-4e73-bb40-77e20c655231"
      },
      "source": [
        "## Prompting Principles\n",
        "- **Principle 1: Write clear and specific instructions**\n",
        "- **Principle 2: Give the model time to “think”**\n",
        "\n",
        "### Tactics\n",
        "\n",
        "#### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
        "- Delimiters can be anything like: ```\n",
        ", `\"\"\"`, `< >`, `<tag> </tag>`, `:`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87121316",
      "metadata": {
        "height": 336,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87121316",
        "outputId": "da67e4b4-bce6-4773-de9c-270f139475c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Providing clear and specific instructions to a model is essential for '\n",
            " 'guiding it towards the desired output and reducing the chances of irrelevant '\n",
            " 'or incorrect responses, even if longer prompts are necessary for clarity and '\n",
            " 'context.')\n"
          ]
        }
      ],
      "source": [
        "# the text to summarize\n",
        "text = f\"\"\"\n",
        "You should express what you want a model to do by \\\n",
        "providing instructions that are as clear and \\\n",
        "specific as you can possibly make them. \\\n",
        "This will guide the model towards the desired output, \\\n",
        "and reduce the chances of receiving irrelevant \\\n",
        "or incorrect responses. Don't confuse writing a \\\n",
        "clear prompt with writing a short prompt. \\\n",
        "In many cases, longer prompts provide more clarity \\\n",
        "and context for the model, which can lead to \\\n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "\n",
        "# the prompt indicating the text above for summarization\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\\n",
        "into a single sentence.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "# get the response\n",
        "response = get_completion(prompt)\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: by formating the prompt this way, we avoid **prompt injection** (that is giving conflicting information to the model) as we specially specified, in another paragraph using `'''` that only the `text` paragraph should be summarized and not anything else."
      ],
      "metadata": {
        "id": "NGHm06xyl3PB"
      },
      "id": "NGHm06xyl3PB"
    },
    {
      "cell_type": "markdown",
      "id": "f2798f3d-7618-4ac5-a6b2-3c69c537903d",
      "metadata": {
        "id": "f2798f3d-7618-4ac5-a6b2-3c69c537903d"
      },
      "source": [
        "#### Tactic 2: Ask for a structured output\n",
        "- JSON, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b50bbbd",
      "metadata": {
        "height": 149,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b50bbbd",
        "outputId": "2ab2e8be-cd89-4dd9-eef3-dde47ff8306d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"book_id\": 1,\n",
            "        \"title\": \"The Midnight Garden\",\n",
            "        \"author\": \"Elena Rivers\",\n",
            "        \"genre\": \"Fantasy\"\n",
            "    },\n",
            "    {\n",
            "        \"book_id\": 2,\n",
            "        \"title\": \"Echoes of the Past\",\n",
            "        \"author\": \"Nathan Black\",\n",
            "        \"genre\": \"Mystery\"\n",
            "    },\n",
            "    {\n",
            "        \"book_id\": 3,\n",
            "        \"title\": \"Whispers in the Wind\",\n",
            "        \"author\": \"Samantha Reed\",\n",
            "        \"genre\": \"Romance\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a list of three made-up book titles along \\\n",
        "with their authors and genres.\n",
        "Provide them in JSON format with the following keys:\n",
        "book_id, title, author, genre.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: we have three fictitious book titles formatted in a json structured as specified, the nice thing with this format is that you can read it in a Python's dictionary or a list. See example below."
      ],
      "metadata": {
        "id": "KYqW8Q6kRurO"
      },
      "id": "KYqW8Q6kRurO"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "json_data = response\n",
        "\n",
        "data = json.loads(json_data)\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqPQmCCrScaa",
        "outputId": "a8c9182c-359f-460a-8d50-c97986aeb6be"
      },
      "id": "oqPQmCCrScaa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'book_id': 1, 'title': 'The Midnight Garden', 'author': 'Elena Rivers', 'genre': 'Fantasy'}, {'book_id': 2, 'title': 'Echoes of the Past', 'author': 'Nathan Black', 'genre': 'Mystery'}, {'book_id': 3, 'title': 'Whispers in the Wind', 'author': 'Samantha Reed', 'genre': 'Romance'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22a71c4f-b1f1-4d67-ad5a-e49fc1e3147d",
      "metadata": {
        "id": "22a71c4f-b1f1-4d67-ad5a-e49fc1e3147d"
      },
      "source": [
        "#### Tactic 3: Ask the model to check whether conditions are satisfied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0ae612e",
      "metadata": {
        "height": 506,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0ae612e",
        "outputId": "d5b4223f-1cb3-45b3-96ef-09d05c581b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "Step 1 - Get some water boiling.\n",
            "Step 2 - Grab a cup and put a tea bag in it.\n",
            "Step 3 - Pour the hot water over the tea bag.\n",
            "Step 4 - Let the tea steep for a few minutes.\n",
            "Step 5 - Remove the tea bag.\n",
            "Step 6 - Add sugar or milk to taste.\n",
            "Step 7 - Enjoy your delicious cup of tea.\n"
          ]
        }
      ],
      "source": [
        "# example of writing specific instructions\n",
        "\n",
        "# Text with instructions - making a cup of tea\n",
        "text_1 = f\"\"\"\n",
        "Making a cup of tea is easy! First, you need to get some \\\n",
        "water boiling. While that's happening, \\\n",
        "grab a cup and put a tea bag in it. Once the water is \\\n",
        "hot enough, just pour it over the tea bag. \\\n",
        "Let it sit for a bit so the tea can steep. After a \\\n",
        "few minutes, take out the tea bag. If you \\\n",
        "like, you can add some sugar or milk to taste. \\\n",
        "And that's it! You've got yourself a delicious \\\n",
        "cup of tea to enjoy.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB1: This prompt explains that the provided text (enclosed in triple quotes) (`\"\"\"`)should be checked to see if it contains a sequence of instructions. If it does, it should reformat them into a step-by-step list. If not, it should return \"No steps provided.\"\n",
        "\n",
        "NB2: Escaping Triple Quotes. `\\\"\\\"\\\"{text_1}\\\"\\\"\\\"` To include triple quotes inside another string, you need to escape each double-quote character with a backslash (`\\\"`). This is necessary to ensure that the triple quotes are treated as part of the string content and not as the end of the string definition."
      ],
      "metadata": {
        "id": "sMPQeFQCUjoD"
      },
      "id": "sMPQeFQCUjoD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76b6cc59",
      "metadata": {
        "height": 506,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76b6cc59",
        "outputId": "368fba53-7ce1-4aca-c358-8b34b36aae8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 2:\n",
            "No steps provided.\n"
          ]
        }
      ],
      "source": [
        "# text without instructions\n",
        "text_2 = f\"\"\"\n",
        "The sun is shining brightly today, and the birds are \\\n",
        "singing. It's a beautiful day to go for a \\\n",
        "walk in the park. The flowers are blooming, and the \\\n",
        "trees are swaying gently in the breeze. People \\\n",
        "are out and about, enjoying the lovely weather. \\\n",
        "Some are having picnics, while others are playing \\\n",
        "games or simply relaxing on the grass. It's a \\\n",
        "perfect day to spend time outdoors and appreciate the \\\n",
        "beauty of nature.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 2:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: the prompt was not able to find instructions from the prompt provided."
      ],
      "metadata": {
        "id": "da4VnwnQUwlH"
      },
      "id": "da4VnwnQUwlH"
    },
    {
      "cell_type": "markdown",
      "id": "3c5866b8-d8c7-4e19-93db-401315f64954",
      "metadata": {
        "id": "3c5866b8-d8c7-4e19-93db-401315f64954"
      },
      "source": [
        "#### Tactic 4: \"Few-shot\" prompting\n",
        "\n",
        "Few-shot prompting is a technique to guide the model in generating desired responses. This is done by providing the model with a few examples (*shots*) of the *input-output pairs* before asking it to generate an output for a new input. The goal is to give the model a sense of the pattern or format it should follow when producing its response. See example below :\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Convert the following sentences into polite form:\n",
        "\n",
        "Example 1:\n",
        "Input: Close the door.\n",
        "Output: Could you please close the door?\n",
        "\n",
        "Example 2:\n",
        "Input: Give me the report.\n",
        "Output: Could you please give me the report?\n",
        "\n",
        "Example 3:\n",
        "Input: Stop talking.\n",
        "Output: Could you please stop talking?\n",
        "\n",
        "Now, convert the following sentence:\n",
        "\n",
        "Input: Pass the salt.\n",
        "Output:\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Few-shot Prompting Applications\n",
        "\n",
        "**Text Transformation**: Rewriting sentences in a specific tone, style, or format.\n",
        "\n",
        "**Question Answering**: Providing examples of how questions should be answered.\n",
        "\n",
        "**Summarization**: Showing examples of how to condense information into summaries.\n",
        "\n",
        "**Translation**: Giving pairs of source and target language sentences to guide translations.\n",
        "\n",
        "**Text Transformation**: Rewriting sentences in a specific tone, style, or format.\n"
      ],
      "metadata": {
        "id": "tVt3nnzHYFDF"
      },
      "id": "tVt3nnzHYFDF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ce1540",
      "metadata": {
        "height": 251,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82ce1540",
        "outputId": "fa5050af-7c84-410e-96e6-fdc972110002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('<grandparent>: Just as a tree bends but does not break in a storm, '\n",
            " 'resilience is the ability to bounce back from adversity. It is the strength '\n",
            " 'to persevere in the face of challenges and setbacks, knowing that every '\n",
            " 'trial is an opportunity for growth.')\n"
          ]
        }
      ],
      "source": [
        "# Example of a conversation between a child and his/her grandparent\n",
        "# the grandparent answer the child with some kind of methaphore\n",
        "# so the prompt answer will apply this tone for the future answer from the child.\n",
        "prompt = f\"\"\"\n",
        "Your task is to answer in a consistent style.\n",
        "\n",
        "<child>: Teach me about patience.\n",
        "\n",
        "<grandparent>: The river that carves the deepest \\\n",
        "valley flows from a modest spring; the \\\n",
        "grandest symphony originates from a single note; \\\n",
        "the most intricate tapestry begins with a solitary thread.\n",
        "\n",
        "<child>: Teach me about resilience.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ece7a8ee-1a2d-415d-8c10-500ecff24b10",
      "metadata": {
        "id": "ece7a8ee-1a2d-415d-8c10-500ecff24b10"
      },
      "source": [
        "### Principle 2: Give the model time to “think”\n",
        "\n",
        "#### Tactic 1: Specify the steps required to complete a task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5e7d6860",
      "metadata": {
        "height": 506,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e7d6860",
        "outputId": "bbabe57e-257f-4b97-d464-2876beb15636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 1:\n",
            "('1 - Jack and Jill go on a quest to fetch water from a well, but encounter '\n",
            " 'misfortune on the way back home.\\n'\n",
            " '\\n'\n",
            " \"2 - Jack et Jill partent en quête d'eau d'un puits, mais rencontrent un \"\n",
            " 'malheur sur le chemin du retour.\\n'\n",
            " '\\n'\n",
            " '3 - Jack, Jill\\n'\n",
            " '\\n'\n",
            " '4 - \\n'\n",
            " '{\\n'\n",
            " '  \"french_summary\": \"Jack et Jill partent en quête d\\'eau d\\'un puits, mais '\n",
            " 'rencontrent un malheur sur le chemin du retour.\",\\n'\n",
            " '  \"num_names\": 2\\n'\n",
            " '}')\n"
          ]
        }
      ],
      "source": [
        "# giving the model time to think\n",
        "text = f\"\"\"\n",
        "In a charming village, siblings Jack and Jill set out on \\\n",
        "a quest to fetch water from a hilltop \\\n",
        "well. As they climbed, singing joyfully, misfortune \\\n",
        "struck—Jack tripped on a stone and tumbled \\\n",
        "down the hill, with Jill following suit. \\\n",
        "Though slightly battered, the pair returned home to \\\n",
        "comforting embraces. Despite the mishap, \\\n",
        "their adventurous spirits remained undimmed, and they \\\n",
        "continued exploring with delight.\n",
        "\"\"\"\n",
        "# example 1\n",
        "prompt_1 = f\"\"\"\n",
        "Perform the following actions:\n",
        "1 - Summarize the following text delimited by triple \\\n",
        "backticks with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the following \\\n",
        "keys: french_summary, num_names.\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt_1)\n",
        "print(\"Completion for prompt 1:\")\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: the text ouput has line breaks (`\\n`) as specified in the prompt."
      ],
      "metadata": {
        "id": "v0LvIVyJfohZ"
      },
      "id": "v0LvIVyJfohZ"
    },
    {
      "cell_type": "markdown",
      "id": "d0bb1dcf-95f5-4ee1-8c25-8b2abd5f0f0d",
      "metadata": {
        "id": "d0bb1dcf-95f5-4ee1-8c25-8b2abd5f0f0d"
      },
      "source": [
        "#### Ask for output in a specified format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e4222cc",
      "metadata": {
        "height": 370,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e4222cc",
        "outputId": "94513558-2343-40d1-f9bd-63dec0a8052f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Completion for prompt 2:\n",
            "Summary: Jack and Jill, two siblings, go on a quest to fetch water from a well on a hill, but encounter misfortune along the way.\n",
            "Translation: Jack et Jill, deux frères et sœurs, partent en quête d'eau d'un puits sur une colline, mais rencontrent des malheurs en chemin.\n",
            "Names: Jack, Jill\n",
            "Output JSON: {\"french_summary\": \"Jack et Jill, deux frères et sœurs, partent en quête d'eau d'un puits sur une colline, mais rencontrent des malheurs en chemin.\", \"num_names\": 2}\n"
          ]
        }
      ],
      "source": [
        "prompt_2 = f\"\"\"\n",
        "Your task is to perform the following actions:\n",
        "1 - Summarize the following text delimited by\n",
        "  <> with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the\n",
        "  following keys: french_summary, num_names.\n",
        "\n",
        "Use the following format:\n",
        "Text: <text to summarize>\n",
        "Summary: <summary>\n",
        "Translation: <summary translation>\n",
        "Names: <list of names in summary>\n",
        "Output JSON: <json with summary and num_names>\n",
        "\n",
        "Text: <{text}>\n",
        "\"\"\"\n",
        "response = get_completion(prompt_2)\n",
        "print(\"\\nCompletion for prompt 2:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: in the example above, we are using `< >` to make reference to our variable text instead of `{ }`.  You can use any delimiter you like that finally will make sense to the model."
      ],
      "metadata": {
        "id": "hXLbUO88gmOn"
      },
      "id": "hXLbUO88gmOn"
    },
    {
      "cell_type": "markdown",
      "id": "fec80fdb-92db-48f6-8f1d-b03c26385bad",
      "metadata": {
        "id": "fec80fdb-92db-48f6-8f1d-b03c26385bad"
      },
      "source": [
        "#### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff5cc985",
      "metadata": {
        "height": 421,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff5cc985",
        "outputId": "449b43da-8345-4ae3-ebcc-69400895c860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"The student's solution is correct. The total cost for the first year of \"\n",
            " 'operations as a function of the number of square feet is indeed 450x + '\n",
            " '100,000.')\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Determine if the student's solution is correct or not.\n",
        "\n",
        "Question:\n",
        "I'm building a solar power installation and I need \\\n",
        " help working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat $100k per year, and an additional $10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations\n",
        "as a function of the number of square feet.\n",
        "\n",
        "Student's Solution:\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f322ebd9-0f8a-43aa-97fe-5eac70cdcc6a",
      "metadata": {
        "id": "f322ebd9-0f8a-43aa-97fe-5eac70cdcc6a"
      },
      "source": [
        "NB: Actually the student's solution is not correct !\n",
        "We can fix this by instructing the model to work out its own solution first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "703f7003",
      "metadata": {
        "height": 999,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "703f7003",
        "outputId": "53d5f11b-a86b-4336-8130-738d931640e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The actual solution is correct.\n",
            "\n",
            "Actual solution:\n",
            "Total cost = Land cost + Solar panel cost + Maintenance cost\n",
            "Total cost = $100x + $250x + $100,000 + $10x\n",
            "Total cost = $360x + $100,000\n",
            "\n",
            "Is the student's solution the same as actual solution just calculated:\n",
            "```\n",
            "No\n",
            "```\n",
            "Student grade:\n",
            "```\n",
            "Incorrect\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to determine if the student's solution \\\n",
        "is correct or not.\n",
        "To solve the problem do the following:\n",
        "- First, work out your own solution to the problem including the final total.\n",
        "- Then compare your solution to the student's solution \\\n",
        "and evaluate if the student's solution is correct or not.\n",
        "Don't decide if the student's solution is correct until\n",
        "you have done the problem yourself.\n",
        "\n",
        "Use the following format:\n",
        "Question:\n",
        "```\n",
        "question here\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "student's solution here\n",
        "```\n",
        "Actual solution:\n",
        "```\n",
        "steps to work out the solution and your solution here\n",
        "```\n",
        "Is the student's solution the same as actual solution \\\n",
        "just calculated:\n",
        "```\n",
        "yes or no\n",
        "```\n",
        "Student grade:\n",
        "```\n",
        "correct or incorrect\n",
        "```\n",
        "\n",
        "Question:\n",
        "```\n",
        "I'm building a solar power installation and I need help \\\n",
        "working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat $100k per year, and an additional $10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations \\\n",
        "as a function of the number of square feet.\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "```\n",
        "Actual solution:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a207eab-a1b1-47a5-b913-fe38086123d0",
      "metadata": {
        "id": "8a207eab-a1b1-47a5-b913-fe38086123d0"
      },
      "source": [
        "## Model Limitations: Hallucinations\n",
        "- Boie is a real company, the product name is not real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81c80919",
      "metadata": {
        "height": 98,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81c80919",
        "outputId": "8184ab74-a052-4324-97b9-340b4a9fc1f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('The AeroGlide UltraSlim Smart Toothbrush by Boie is a high-tech toothbrush '\n",
            " 'designed to provide a superior cleaning experience. It features a slim and '\n",
            " 'sleek design that makes it easy to hold and maneuver in the mouth. The '\n",
            " 'toothbrush is equipped with smart technology that tracks your brushing '\n",
            " 'habits and provides real-time feedback to help you improve your oral hygiene '\n",
            " 'routine.\\n'\n",
            " '\\n'\n",
            " 'The AeroGlide UltraSlim Smart Toothbrush also has soft, tapered bristles '\n",
            " 'that are gentle on the gums and teeth, making it suitable for those with '\n",
            " 'sensitive mouths. The bristles are made from a durable and hygienic material '\n",
            " 'that is resistant to bacteria growth, ensuring a clean and healthy brushing '\n",
            " 'experience.\\n'\n",
            " '\\n'\n",
            " 'Overall, the AeroGlide UltraSlim Smart Toothbrush by Boie is a cutting-edge '\n",
            " 'toothbrush that combines advanced technology with high-quality materials to '\n",
            " 'provide a superior cleaning experience for users.')\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eea88a6e-0141-4296-a73b-6b2282fe0de6",
      "metadata": {
        "id": "eea88a6e-0141-4296-a73b-6b2282fe0de6"
      },
      "source": [
        "## Try experimenting on your own!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77457878",
      "metadata": {
        "height": 30,
        "id": "77457878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70055066-eede-4aeb-f8dc-37c1fbf88f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('La supercar de Peugeot dont vous parlez est probablement la Peugeot 908 RC, '\n",
            " 'un concept car dévoilé en 2006. Cette voiture de sport de luxe était équipée '\n",
            " \"d'un moteur V12 diesel de 5,5 litres développant 700 chevaux, ce qui lui \"\n",
            " \"permettait d'atteindre une vitesse maximale de 300 km/h. La Peugeot 908 RC \"\n",
            " \"était également dotée d'un design élégant et futuriste, avec des portes \"\n",
            " 'papillon et un intérieur luxueux en cuir et en aluminium. Malheureusement, '\n",
            " \"ce concept car n'a jamais été produit en série et reste un modèle unique.\")\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Donne moi des infos à propos de cette voiture supercar de Peugeot\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Qui a écrit le livre \"Les Mondes d'Aldébaran\" ?\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "pprint(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isGlpngio0Uf",
        "outputId": "f42f224f-33d7-484b-a99b-087ff74161d4"
      },
      "id": "isGlpngio0Uf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Le livre \"Les Mondes d\\'Aldébaran\" a été écrit par le scénariste et '\n",
            " 'dessinateur de bande dessinée français, Leo.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02294fd1-bc42-416a-b0cb-34d6d22b20cd",
      "metadata": {
        "id": "02294fd1-bc42-416a-b0cb-34d6d22b20cd"
      },
      "source": [
        "#### Notes on using the OpenAI API outside of this classroom\n",
        "\n",
        "To install the OpenAI Python library:\n",
        "```\n",
        "!pip install openai\n",
        "```\n",
        "\n",
        "The library needs to be configured with your account's secret key, which is available on the [website](https://platform.openai.com/account/api-keys).\n",
        "\n",
        "You can either set it as the `OPENAI_API_KEY` environment variable before using the library:\n",
        " ```\n",
        " !export OPENAI_API_KEY='sk-...'\n",
        " ```\n",
        "\n",
        "Or, set `openai.api_key` to its value:\n",
        "\n",
        "```\n",
        "import openai\n",
        "openai.api_key = \"sk-...\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2ef0aa7-77e5-465e-a0ac-21c7156c9339",
      "metadata": {
        "id": "a2ef0aa7-77e5-465e-a0ac-21c7156c9339"
      },
      "source": [
        "#### A note about the backslash\n",
        "- In the course, we are using a backslash `\\` to make the text fit on the screen without inserting newline '\\n' characters.\n",
        "- GPT-3 isn't really affected whether you insert newline characters or not.  But when working with LLMs in general, you may consider whether newline characters in your prompt may affect the model's performance.\n",
        "\n",
        "Here is a more detailed explanation:\n",
        "\n",
        "Using backslashes () instead of line returns in prompts can be beneficial for several reasons:\n",
        "\n",
        "- Readability in code: It allows you to write long prompts across multiple lines in your code without actually inserting line breaks into the prompt text itself. This makes your code more readable while keeping the prompt as a single continuous string.\n",
        "- Consistency: Some AI models might interpret actual line breaks differently, potentially affecting the output. Using \\ ensures the prompt is processed as one continuous piece of text.\n",
        "- Easier string manipulation: When the entire prompt is on one logical line in your code, it's often easier to perform string operations or modifications if needed.\n",
        "- Avoiding unintended formatting: In some contexts, actual line breaks might be interpreted as formatting (e.g., in Markdown), which could alter the meaning of your prompt.-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f92c1dcc-1cef-42f7-9291-fa1dfa9fcc1b",
      "metadata": {
        "height": 30,
        "id": "f92c1dcc-1cef-42f7-9291-fa1dfa9fcc1b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}