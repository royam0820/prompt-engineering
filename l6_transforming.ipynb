{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royam0820/prompt-engineering/blob/main/l6_transforming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3993515-9710-4ac4-89e9-b35ebb81e920",
      "metadata": {
        "id": "e3993515-9710-4ac4-89e9-b35ebb81e920"
      },
      "source": [
        "# Transforming\n",
        "\n",
        "In this notebook, we will explore how to use Large Language Models for text transformation tasks such as language translation, spelling and grammar checking, tone adjustment, and format conversion.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "1VL1vEva97yI"
      },
      "id": "1VL1vEva97yI"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ued_418AogZz",
        "outputId": "0504c243-c8e6-4242-8c29-d7770d3cebee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.34.0\n"
          ]
        }
      ],
      "id": "Ued_418AogZz"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "m39DjFvJoI0H"
      },
      "execution_count": null,
      "outputs": [],
      "id": "m39DjFvJoI0H"
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "FBexQysn5fl5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "FBexQysn5fl5"
    },
    {
      "cell_type": "code",
      "source": [
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dswy5j-noziQ",
        "outputId": "387ab52e-07ba-4b97-bc2f-7637cf51cd3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.34.0\n"
          ]
        }
      ],
      "id": "dswy5j-noziQ"
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "JzhXT5sAnTLA"
      },
      "execution_count": null,
      "outputs": [],
      "id": "JzhXT5sAnTLA"
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI()\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "47w3YM77pZG6"
      },
      "execution_count": null,
      "outputs": [],
      "id": "47w3YM77pZG6"
    },
    {
      "cell_type": "markdown",
      "id": "1d8f0bd8-628e-4c36-bcd0-2110162f25fc",
      "metadata": {
        "id": "1d8f0bd8-628e-4c36-bcd0-2110162f25fc"
      },
      "source": [
        "## Translation\n",
        "\n",
        "ChatGPT is trained with sources in many languages. This gives the model the ability to do translation. Here are some examples of how to use this capability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c4df6ff",
      "metadata": {
        "height": 115,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c4df6ff",
        "outputId": "af6508df-84c2-465b-85eb-5b8cc8191882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola, me gustaría ordenar una licuadora.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following English text to Spanish: \\\n",
        "```Hi, I would like to order a blender```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7300ed9b",
      "metadata": {
        "height": 115,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7300ed9b",
        "outputId": "859e8f36-12d8-40a3-e620-017f36e8764b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me which language this is:\n",
        "```Combien coûte le lampadaire?```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791e789b",
      "metadata": {
        "height": 132,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "791e789b",
        "outputId": "698e3238-b2e5-443e-db46-4bd21cdb7d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French: ```Je veux commander un ballon de basket```\n",
            "\n",
            "Spanish: ```Quiero ordenar un balón de baloncesto```\n",
            "\n",
            "Pirate English: ```I be wantin' to order a basketball```\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following  text to French and Spanish\n",
        "and English pirate: \\\n",
        "```I want to order a basketball```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf7eb63",
      "metadata": {
        "height": 132,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcf7eb63",
        "outputId": "822d2125-87c7-4351-8315-55fc249c1269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formal: ¿Le gustaría ordenar una almohada?\n",
            "Informal: ¿Te gustaría ordenar una almohada?\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following text to Spanish in both the \\\n",
        "formal and informal forms:\n",
        "'Would you like to order a pillow?'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8edb56d2-a32a-470f-9f40-4fc5b1ea0849",
      "metadata": {
        "id": "8edb56d2-a32a-470f-9f40-4fc5b1ea0849"
      },
      "source": [
        "### Universal Translator\n",
        "Imagine you are in charge of IT at a large multinational e-commerce company. Users are messaging you with IT issues in all their native languages. Your staff is from all over the world and speaks only their native languages. You need a universal translator!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a40bf0",
      "metadata": {
        "height": 132,
        "tags": [],
        "id": "68a40bf0"
      },
      "outputs": [],
      "source": [
        "user_messages = [\n",
        "  \"La performance du système est plus lente que d'habitude.\",  # System performance is slower than normal\n",
        "  \"Mi monitor tiene píxeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n",
        "  \"Il mio mouse non funziona\",                                 # My mouse is not working\n",
        "  \"Mój klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n",
        "  \"我的屏幕在闪烁\"                                               # My screen is flashing\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552d0db9",
      "metadata": {
        "height": 200,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "552d0db9",
        "outputId": "4c094d6a-a9c2-4ff9-95e6-4e23c2cf3569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original message (This is French.): La performance du système est plus lente que d'habitude.\n",
            "English: \"The system performance is slower than usual.\"\n",
            "\n",
            "Korean: \"시스템 성능이 평소보다 느립니다.\" \n",
            "\n",
            "Original message (This is Spanish.): Mi monitor tiene píxeles que no se iluminan.\n",
            "English: \"My monitor has pixels that do not light up.\"\n",
            "Korean: \"내 모니터에는 불이 켜지지 않는 픽셀이 있습니다.\" \n",
            "\n",
            "Original message (Italian): Il mio mouse non funziona\n",
            "English: My mouse is not working\n",
            "Korean: 내 마우스가 작동하지 않습니다 \n",
            "\n",
            "Original message (This is Polish.): Mój klawisz Ctrl jest zepsuty\n",
            "English: My Ctrl key is broken\n",
            "Korean: 제 Ctrl 키가 고장 났어요 \n",
            "\n",
            "Original message (This is Chinese.): 我的屏幕在闪烁\n",
            "English: My screen is flickering\n",
            "Korean: 내 화면이 깜박거립니다 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for issue in user_messages:\n",
        "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
        "    lang = get_completion(prompt)\n",
        "    print(f\"Original message ({lang}): {issue}\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Translate the following  text to English \\\n",
        "    and Korean: ```{issue}```\n",
        "    \"\"\"\n",
        "    response = get_completion(prompt)\n",
        "    print(response, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18e660eb-324f-474c-acf3-7e3bf5b7c70e",
      "metadata": {
        "id": "18e660eb-324f-474c-acf3-7e3bf5b7c70e"
      },
      "source": [
        "## Try it yourself!\n",
        "Try some translations on your own!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa57158f-d77d-42d1-94fe-17fa59c012f8",
      "metadata": {
        "height": 30,
        "id": "fa57158f-d77d-42d1-94fe-17fa59c012f8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1d9e54ca-f93a-43c8-a295-bff7a89f77f5",
      "metadata": {
        "id": "1d9e54ca-f93a-43c8-a295-bff7a89f77f5"
      },
      "source": [
        "## Tone Transformation\n",
        "Writing can vary based on the intended audience. ChatGPT can produce different tones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2deac328",
      "metadata": {
        "height": 115,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2deac328",
        "outputId": "63f0d0da-34a3-492a-d54a-b01c017541fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Sir/Madam,\n",
            "\n",
            "I am writing to bring to your attention the specifications of the standing lamp. \n",
            "\n",
            "Sincerely,\n",
            "Joe\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following from slang to a business letter:\n",
        "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2c7eb73-6b82-442d-b4f8-251c308e89d5",
      "metadata": {
        "id": "a2c7eb73-6b82-442d-b4f8-251c308e89d5"
      },
      "source": [
        "## Format Conversion\n",
        "ChatGPT can translate between formats. The prompt should describe the input and output formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a37f0a0",
      "metadata": {
        "height": 217,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a37f0a0",
        "outputId": "4a8f880d-72be-4258-c54d-dde04bdad0ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html>\n",
            "<head>\n",
            "  <title>Restaurant Employees</title>\n",
            "</head>\n",
            "<body>\n",
            "  <table>\n",
            "    <tr>\n",
            "      <th>Name</th>\n",
            "      <th>Email</th>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Shyam</td>\n",
            "      <td>shyamjaiswal@gmail.com</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Bob</td>\n",
            "      <td>bob32@gmail.com</td>\n",
            "    </tr>\n",
            "    <tr>\n",
            "      <td>Jai</td>\n",
            "      <td>jai87@gmail.com</td>\n",
            "    </tr>\n",
            "  </table>\n",
            "</body>\n",
            "</html>\n"
          ]
        }
      ],
      "source": [
        "data_json = { \"resturant employees\" :[\n",
        "    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n",
        "    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
        "    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
        "]}\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Translate the following python dictionary from JSON to an HTML \\\n",
        "table with column headers and title: {data_json}\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "481a46b7",
      "metadata": {
        "height": 47,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "481a46b7",
        "outputId": "eee8420b-5ad4-4a5a-c0d9-c15ba49a62b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<html>\n",
              "<head>\n",
              "  <title>Restaurant Employees</title>\n",
              "</head>\n",
              "<body>\n",
              "  <table>\n",
              "    <tr>\n",
              "      <th>Name</th>\n",
              "      <th>Email</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Shyam</td>\n",
              "      <td>shyamjaiswal@gmail.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Bob</td>\n",
              "      <td>bob32@gmail.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Jai</td>\n",
              "      <td>jai87@gmail.com</td>\n",
              "    </tr>\n",
              "  </table>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, Markdown, Latex, HTML, JSON\n",
        "display(HTML(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df1824c-534b-45cb-b0c1-3000bba5adbe",
      "metadata": {
        "id": "2df1824c-534b-45cb-b0c1-3000bba5adbe"
      },
      "source": [
        "## Spellcheck/Grammar check.\n",
        "\n",
        "Here are some examples of common grammar and spelling problems and the LLM's response.\n",
        "\n",
        "To signal to the LLM that you want it to proofread your text, you instruct the model to 'proofread' or 'proofread and correct'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d77283",
      "metadata": {
        "height": 302,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52d77283",
        "outputId": "961a9243-453b-4493-f96f-4624e3e68b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The girl with the black and white puppies has a ball.\n",
            "No errors found\n",
            "No errors found.\n",
            "Their goes my freedom. There going to bring they’re suitcases.\n",
            "\n",
            "No errors found.\n",
            "\n",
            "Rewritten:\n",
            "Their goes my freedom. There going to bring their suitcases.\n",
            "You're going to need your notebook.\n",
            "No errors found.\n",
            "No errors found\n"
          ]
        }
      ],
      "source": [
        "text = [\n",
        "  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
        "  \"Yolanda has her notebook.\", # ok\n",
        "  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms\n",
        "  \"Their goes my freedom. There going to bring they’re suitcases.\",  # Homonyms\n",
        "  \"Your going to need you’re notebook.\",  # Homonyms\n",
        "  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms\n",
        "  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling\n",
        "]\n",
        "for t in text:\n",
        "    prompt = f\"\"\"Proofread and correct the following text\n",
        "    and rewrite the corrected version. If you don't find\n",
        "    and errors, just say \"No errors found\". Don't use\n",
        "    any punctuation around the text:\n",
        "    ```{t}```\"\"\"\n",
        "    response = get_completion(prompt)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7543fe7d",
      "metadata": {
        "height": 234,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7543fe7d",
        "outputId": "67a57c37-5a69-4224-9c14-981b27143454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Got this for my daughter for her birthday because she keeps taking mine from '\n",
            " 'my room. Yes, adults also like pandas too. She takes it everywhere with her, '\n",
            " \"and it's super soft and cute. One of the ears is a bit lower than the other, \"\n",
            " \"and I don't think that was designed to be asymmetrical. It's a bit small for \"\n",
            " 'what I paid for it though. I think there might be other options that are '\n",
            " 'bigger for the same price. It arrived a day earlier than expected, so I got '\n",
            " 'to play with it myself before I gave it to my daughter.')\n"
          ]
        }
      ],
      "source": [
        "text = f\"\"\"\n",
        "Got this for my daughter for her birthday cuz she keeps taking \\\n",
        "mine from my room.  Yes, adults also like pandas too.  She takes \\\n",
        "it everywhere with her, and it's super soft and cute.  One of the \\\n",
        "ears is a bit lower than the other, and I don't think that was \\\n",
        "designed to be asymmetrical. It's a bit small for what I paid for it \\\n",
        "though. I think there might be other options that are bigger for \\\n",
        "the same price.  It arrived a day earlier than expected, so I got \\\n",
        "to play with it myself before I gave it to my daughter.\n",
        "\"\"\"\n",
        "prompt = f\"proofread and correct this review: ```{text}```\"\n",
        "response = get_completion(prompt)\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install redlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nmpWOnxw-tJH",
        "outputId": "8a70cea7-f5a4-4a3e-fb96-348068e5b6f3"
      },
      "id": "nmpWOnxw-tJH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting redlines\n",
            "  Downloading redlines-0.4.2-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from redlines) (8.1.7)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.3.5 in /usr/local/lib/python3.10/dist-packages (from redlines) (13.7.1)\n",
            "Collecting rich-click<2.0.0,>=1.6.1 (from redlines)\n",
            "  Downloading rich_click-1.8.3-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.3.5->redlines) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.3.5->redlines) (2.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from rich-click<2.0.0,>=1.6.1->redlines) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.3.5->redlines) (0.1.2)\n",
            "Installing collected packages: rich-click, redlines\n",
            "Successfully installed redlines-0.4.2 rich-click-1.8.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the redlines\n",
        "from redlines import Redlines\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Example texts for comparison\n",
        "text = \"This is the original text.\"\n",
        "response = \"This is the modified text.\"\n",
        "\n",
        "# Create a Redlines object\n",
        "diff = Redlines(text, response)\n",
        "\n",
        "# Display the markdown output\n",
        "display(Markdown(diff.output_markdown))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "BXJWglCTA29Z",
        "outputId": "aaca14b2-0e58-484a-abe5-adaffec04ad8"
      },
      "id": "BXJWglCTA29Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This is the <span style='color:red;font-weight:700;text-decoration:line-through;'>original </span><span style='color:green;font-weight:700;'>modified </span>text."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: redlines not working in Google Colab ;-("
      ],
      "metadata": {
        "id": "sSw7tgO9AZ6D"
      },
      "id": "sSw7tgO9AZ6D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11ac80a0",
      "metadata": {
        "height": 81,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "11ac80a0",
        "outputId": "60ccf712-bcbf-4d05-ed5e-23c660d676a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Got this for my daughter for her birthday <span style='color:red;font-weight:700;text-decoration:line-through;'>cuz </span><span style='color:green;font-weight:700;'>because </span>she keeps taking mine from my <span style='color:red;font-weight:700;text-decoration:line-through;'>room.  </span><span style='color:green;font-weight:700;'>room. </span>Yes, adults also like pandas <span style='color:red;font-weight:700;text-decoration:line-through;'>too.  </span><span style='color:green;font-weight:700;'>too. </span>She takes it everywhere with her, and it's super soft and <span style='color:red;font-weight:700;text-decoration:line-through;'>cute.  </span><span style='color:green;font-weight:700;'>cute. </span>One of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. It's a bit small for what I paid for it though. I think there might be other options that are bigger for the same <span style='color:red;font-weight:700;text-decoration:line-through;'>price.  </span><span style='color:green;font-weight:700;'>price. </span>It arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter."
          },
          "metadata": {}
        }
      ],
      "source": [
        "from redlines import Redlines\n",
        "\n",
        "diff = Redlines(text,response)\n",
        "display(Markdown(diff.output_markdown))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b4e73fd",
      "metadata": {
        "height": 149,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "2b4e73fd",
        "outputId": "285aa855-dcef-4c3d-e486-89dbf3926276"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I purchased this adorable panda plush as a birthday gift for my daughter, as she kept borrowing mine from my room. It's worth noting that adults can also appreciate the charm of pandas. The plush is incredibly soft and cute, becoming her constant companion wherever she goes. However, I did notice a slight asymmetry in the ears, which I believe was not intentional in the design. Despite this minor flaw, I found the size to be a bit smaller than expected given the price point. I suspect there may be larger options available for the same cost. On a positive note, the plush arrived a day earlier than anticipated, allowing me to enjoy its cuddly features before presenting it to my daughter. Overall, while there are some room for improvement, the quality and timely delivery of this panda plush make it a worthwhile purchase for any panda enthusiast."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "proofread and correct this review. Make it more compelling.\n",
        "Ensure it follows APA style guide and targets an advanced reader.\n",
        "Output in markdown format.\n",
        "Text: ```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63fb76bc-a742-4b35-9dc2-f7fbc12d38fb",
      "metadata": {
        "id": "63fb76bc-a742-4b35-9dc2-f7fbc12d38fb"
      },
      "source": [
        "## Try it yourself!\n",
        "Try changing the instructions to form your own review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2b2ca58",
      "metadata": {
        "height": 30,
        "id": "a2b2ca58"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3dbf5020-7d7f-4ba5-840b-20e883cd7c99",
      "metadata": {
        "id": "3dbf5020-7d7f-4ba5-840b-20e883cd7c99"
      },
      "source": [
        "Thanks to the following sites:\n",
        "\n",
        "https://writingprompts.com/bad-grammar-examples/\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}