{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royam0820/prompt-engineering/blob/main/l7_expanding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8de529e8-3891-4f47-8585-65b92b80bbf7",
      "metadata": {
        "id": "8de529e8-3891-4f47-8585-65b92b80bbf7"
      },
      "source": [
        "# Expanding\n",
        "In this lesson, you will generate customer service emails that are tailored to each customer's review.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expanding prompts** in prompting techniques refers to the **method of providing more detailed**, specific, and comprehensive prompts to elicit better and more accurate responses from a language model. **The idea is to give the model enough context and information to generate useful and relevant outputs**. Here are the key aspects and steps involved in the expanding technique:\n",
        "\n",
        "**Starting with a Simple Prompt**: Begin with a straightforward and concise prompt. This helps in understanding how the model responds to basic queries.\n",
        "\n",
        "**Adding Context**: Include additional background information or context relevant to the prompt. This helps the model understand the broader situation or specific details that might influence the response.\n",
        "\n",
        "**Specifying Requirements**: Clearly state any specific requirements or constraints. For example, if a particular format, length, or style is needed, this should be specified in the prompt.\n",
        "\n",
        "**Including Examples**: Providing examples of desired outputs can guide the model in generating similar responses. This can help in aligning the output with the expected quality and structure.\n",
        "\n",
        "**Using Follow-up Questions**: Anticipate potential ambiguities or areas where more detail might be needed and include follow-up questions in the prompt.\n",
        "\n",
        "**Iterative Refinement**: After reviewing the initial response, refine and expand the prompt further based on any gaps or inaccuracies in the output. This iterative process helps in honing the prompt for the best results."
      ],
      "metadata": {
        "id": "OoEB04v7ueQW"
      },
      "id": "OoEB04v7ueQW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "APq81DDToICJ"
      },
      "id": "APq81DDToICJ"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ued_418AogZz",
        "outputId": "a0a5d591-333d-478c-df54-2decc61c0e79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.3\n"
          ]
        }
      ],
      "id": "Ued_418AogZz"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "m39DjFvJoI0H"
      },
      "execution_count": 2,
      "outputs": [],
      "id": "m39DjFvJoI0H"
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "FBexQysn5fl5"
      },
      "execution_count": 3,
      "outputs": [],
      "id": "FBexQysn5fl5"
    },
    {
      "cell_type": "code",
      "source": [
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dswy5j-noziQ",
        "outputId": "c11a0a79-d55a-40e6-c875-3f3b83c2f84b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.35.3\n"
          ]
        }
      ],
      "id": "dswy5j-noziQ"
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "JzhXT5sAnTLA"
      },
      "execution_count": 5,
      "outputs": [],
      "id": "JzhXT5sAnTLA"
    },
    {
      "cell_type": "code",
      "source": [
        "# client = openai.OpenAI()\n",
        "\n",
        "# def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "#     messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "#     response = client.chat.completions.create(\n",
        "#         model=model,\n",
        "#         messages=messages,\n",
        "#         temperature=0\n",
        "#     )\n",
        "#     return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "47w3YM77pZG6"
      },
      "execution_count": null,
      "outputs": [],
      "id": "47w3YM77pZG6"
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI()\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\",temperature=0):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    # Access the content directly from the 'message' attribute\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "ZRj8ktP-pooV"
      },
      "id": "ZRj8ktP-pooV",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f8ceea77-990a-4c64-bb49-3ba65eb155d2",
      "metadata": {
        "id": "f8ceea77-990a-4c64-bb49-3ba65eb155d2"
      },
      "source": [
        "## Customize the automated reply to a customer email"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c30c4239",
      "metadata": {
        "height": 642,
        "id": "c30c4239"
      },
      "outputs": [],
      "source": [
        "# given the sentiment from the lesson on \"inferring\",\n",
        "# and the original customer message, customize the email\n",
        "sentiment = \"negative\"\n",
        "\n",
        "# review for a blender\n",
        "review = f\"\"\"\n",
        "So, they still had the 17 piece system on seasonal \\\n",
        "sale for around $49 in the month of November, about \\\n",
        "half off, but for some reason (call it price gouging) \\\n",
        "around the second week of December the prices all went \\\n",
        "up to about anywhere from between $70-$89 for the same \\\n",
        "system. And the 11 piece system went up around $10 or \\\n",
        "so in price also from the earlier sale price of $29. \\\n",
        "So it looks okay, but if you look at the base, the part \\\n",
        "where the blade locks into place doesn’t look as good \\\n",
        "as in previous editions from a few years ago, but I \\\n",
        "plan to be very gentle with it (example, I crush \\\n",
        "very hard items like beans, ice, rice, etc. in the \\\n",
        "blender first then pulverize them in the serving size \\\n",
        "I want in the blender then switch to the whipping \\\n",
        "blade for a finer flour, and use the cross cutting blade \\\n",
        "first when making smoothies, then use the flat blade \\\n",
        "if I need them finer/less pulpy). Special tip when making \\\n",
        "smoothies, finely cut and freeze the fruits and \\\n",
        "vegetables (if using spinach-lightly stew soften the \\\n",
        "spinach then freeze until ready for use-and if making \\\n",
        "sorbet, use a small to medium sized food processor) \\\n",
        "that you plan to use that way you can avoid adding so \\\n",
        "much ice if at all-when making your smoothie. \\\n",
        "After about a year, the motor was making a funny noise. \\\n",
        "I called customer service but the warranty expired \\\n",
        "already, so I had to buy another one. FYI: The overall \\\n",
        "quality has gone done in these types of products, so \\\n",
        "they are kind of counting on brand recognition and \\\n",
        "consumer loyalty to maintain sales. Got it in about \\\n",
        "two days.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d5403f73",
      "metadata": {
        "height": 302,
        "id": "d5403f73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b04139-4889-4e3e-9423-df278fd6c1ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear valued customer,\n",
            "\n",
            "Thank you for taking the time to share your detailed feedback with us. We are truly sorry to hear about the issues you experienced with the pricing changes and the quality of the product. We apologize for any inconvenience this may have caused you.\n",
            "\n",
            "If you have any further concerns or would like to discuss this matter further, please feel free to reach out to our customer service team. They will be more than happy to assist you.\n",
            "\n",
            "We appreciate your loyalty and feedback as it helps us improve our products and services for all our customers.\n",
            "\n",
            "Thank you again for your review.\n",
            "\n",
            "AI customer agent\n"
          ]
        }
      ],
      "source": [
        "# we are going to make a reply based on the sentiment extracted, in this case negative\n",
        "prompt = f\"\"\"\n",
        "You are a customer service AI assistant.\n",
        "Your task is to send an email reply to a valued customer.\n",
        "Given the customer email delimited by ```, \\\n",
        "Generate a reply to thank the customer for their review.\n",
        "If the sentiment is positive or neutral, thank them for \\\n",
        "their review.\n",
        "If the sentiment is negative, apologize and suggest that \\\n",
        "they can reach out to customer service.\n",
        "Make sure to use specific details from the review.\n",
        "Write in a concise and professional tone.\n",
        "Sign the email as `AI customer agent`.\n",
        "Customer review: ```{review}```\n",
        "Review sentiment: {sentiment}\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx_jCt1jYuCG",
        "outputId": "504ef538-7df0-42e3-8ba4-5120724f32c8"
      },
      "id": "Zx_jCt1jYuCG",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Dear Valued Customer,\\n'\n",
            " '\\n'\n",
            " 'Thank you for taking the time to share your detailed feedback with us. We '\n",
            " 'are truly sorry to hear about your experience with the pricing fluctuations '\n",
            " 'and the decrease in quality of the product. We apologize for any '\n",
            " 'inconvenience this may have caused you.\\n'\n",
            " '\\n'\n",
            " 'If you have any further concerns or would like to discuss this matter '\n",
            " 'further, please do not hesitate to reach out to our customer service team. '\n",
            " 'They will be more than happy to assist you with any issues you may have '\n",
            " 'encountered.\\n'\n",
            " '\\n'\n",
            " 'We appreciate your loyalty and feedback as it helps us improve our products '\n",
            " 'and services for all our customers.\\n'\n",
            " '\\n'\n",
            " 'Thank you once again for your review.\\n'\n",
            " '\\n'\n",
            " 'AI customer agent')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: as per the example above, it is important to notify the customer that the answer has been generated by an AI bot."
      ],
      "metadata": {
        "id": "jH0GvTwzwnLc"
      },
      "id": "jH0GvTwzwnLc"
    },
    {
      "cell_type": "markdown",
      "id": "55605ee0-118c-4c46-a917-4981a43fcad3",
      "metadata": {
        "id": "55605ee0-118c-4c46-a917-4981a43fcad3"
      },
      "source": [
        "## Remind the model to use details from the customer's email"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model temperature\n",
        "Model temperature is a parameter used in language models like GPT to control the randomness and creativity of the generated text. It influences the probability distribution from which the model selects the next word in the sequence. Understanding and adjusting the temperature can significantly affect the behavior of the model's outputs."
      ],
      "metadata": {
        "id": "4yavK2i9ynaP"
      },
      "id": "4yavK2i9ynaP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is Model Temperature?\n",
        "Temperature is a hyperparameter that scales the logits (the raw predictions) before applying the softmax function to generate probabilities. It modifies the probability distribution of the possible next words, making the output either more deterministic or more random.\n",
        "\n",
        "### How Temperature Works\n",
        "- **High Temperature (>1)**: Increases randomness by flattening the probability distribution. This means the model is more likely to select less probable words, leading to more diverse and creative outputs. However, it might also result in less coherent or off-topic responses.\n",
        "- **Low Temperature (<1)**: Decreases randomness by making the probability distribution sharper. This makes the model more likely to select the most probable words, leading to more predictable and conservative outputs. Very low temperatures can make the output repetitive and dull.\n",
        "- **Temperature = 1**: The model generates text based on the original probabilities without any scaling. It’s a balanced setting where the output is neither too random nor too deterministic.\n",
        "\n",
        "### Choosing the Right Temperature\n",
        "- **Creative Writing**: Use a higher temperature to encourage more diverse and imaginative text.\n",
        "- **Technical Writing**: Use a lower temperature to ensure clarity, precision, and coherence.\n",
        "- **Balanced Text Generation**: Use a temperature around 1 to maintain a balance between creativity and predictability.\n"
      ],
      "metadata": {
        "id": "NYznq0wjy47M"
      },
      "id": "NYznq0wjy47M"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1d5ea7c8",
      "metadata": {
        "height": 302,
        "id": "1d5ea7c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e92496-be52-480a-e8f5-3c061d7aeaa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Valued Customer,\n",
            "\n",
            "Thank you for taking the time to share your detailed feedback with us. We are truly sorry to hear about your experience with the pricing fluctuations and the decrease in quality of the product. We apologize for any inconvenience this may have caused you.\n",
            "\n",
            "If you have any further concerns or would like to discuss this matter further, please do not hesitate to reach out to our customer service team. They will be more than happy to assist you with any issues you may have encountered.\n",
            "\n",
            "We appreciate your loyalty and feedback as it helps us improve our products and services for all our customers.\n",
            "\n",
            "Thank you once again for your review.\n",
            "\n",
            "AI customer agent\n"
          ]
        }
      ],
      "source": [
        "# using a higher temperature (0.7) to get a bit more creative\n",
        "prompt = f\"\"\"\n",
        "You are a customer service AI assistant.\n",
        "Your task is to send an email reply to a valued customer.\n",
        "Given the customer email delimited by ```, \\\n",
        "Generate a reply to thank the customer for their review.\n",
        "If the sentiment is positive or neutral, thank them for \\\n",
        "their review.\n",
        "If the sentiment is negative, apologize and suggest that \\\n",
        "they can reach out to customer service.\n",
        "Make sure to use specific details from the review.\n",
        "Write in a concise and professional tone.\n",
        "Sign the email as `AI customer agent`.\n",
        "Customer review: ```{review}```\n",
        "Review sentiment: {sentiment}\n",
        "\"\"\"\n",
        "response = get_completion(prompt, temperature=0.7)    # changing the temperature from 0 to 0.7\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrcz7LEcYo0I",
        "outputId": "29067464-1eef-4bd0-825e-53c7aacc253d"
      },
      "id": "Lrcz7LEcYo0I",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Dear Valued Customer,\\n'\n",
            " '\\n'\n",
            " 'Thank you for taking the time to share your detailed feedback with us. We '\n",
            " 'are truly sorry to hear about your experience with the pricing fluctuations '\n",
            " 'and the decrease in quality of the product. We apologize for any '\n",
            " 'inconvenience this may have caused you.\\n'\n",
            " '\\n'\n",
            " 'If you have any further concerns or would like to discuss this matter '\n",
            " 'further, please do not hesitate to reach out to our customer service team. '\n",
            " 'They will be more than happy to assist you with any issues you may have '\n",
            " 'encountered.\\n'\n",
            " '\\n'\n",
            " 'We appreciate your loyalty and feedback as it helps us improve our products '\n",
            " 'and services for all our customers.\\n'\n",
            " '\\n'\n",
            " 'Thank you once again for your review.\\n'\n",
            " '\\n'\n",
            " 'AI customer agent')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31e317ad-9e51-4e7a-90c3-d88e7bf8a98c",
      "metadata": {
        "id": "31e317ad-9e51-4e7a-90c3-d88e7bf8a98c"
      },
      "source": [
        "## Try experimenting on your own!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giving a technical discussion about Machine Learning for an audience with basic understanding of computer science."
      ],
      "metadata": {
        "id": "BqD1mISD0Jcj"
      },
      "id": "BqD1mISD0Jcj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffa65c7e",
      "metadata": {
        "height": 30,
        "id": "ffa65c7e"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "Explain machine learning.\n",
        "Machine learning is a subfield of artificial intelligence that focuses on the development of algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. Explain machine learning in detail, covering the following aspects:\n",
        "1. Definition and key concepts\n",
        "2. Types of machine learning (supervised, unsupervised, reinforcement learning)\n",
        "3. Common algorithms used in machine learning\n",
        "4. Applications of machine learning in various industries\n",
        "5. Potential challenges and ethical considerations\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Use clear and concise language suitable for an audience with a basic understanding of computer science to explaing \\\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53MnSDfrvopk",
        "outputId": "1823616d-aca1-4ac2-e1f5-d4b8535e6643"
      },
      "id": "53MnSDfrvopk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Machine learning is a branch of artificial intelligence that involves the development of algorithms and statistical models that allow computers to learn from and make predictions or decisions based on data without being explicitly programmed.\n",
            "\n",
            "2. There are three main types of machine learning:\n",
            "- Supervised learning: In this type, the algorithm is trained on labeled data, where the correct output is provided. The algorithm learns to map inputs to outputs based on the provided examples.\n",
            "- Unsupervised learning: Here, the algorithm is trained on unlabeled data and must find patterns or relationships within the data on its own.\n",
            "- Reinforcement learning: This type involves training an algorithm to make sequential decisions by rewarding or punishing it based on its actions.\n",
            "\n",
            "3. Common algorithms used in machine learning include:\n",
            "- Linear regression\n",
            "- Decision trees\n",
            "- Support vector machines\n",
            "- Neural networks\n",
            "- K-means clustering\n",
            "\n",
            "4. Machine learning is used in various industries for tasks such as:\n",
            "- Predictive analytics in finance\n",
            "- Image and speech recognition in healthcare\n",
            "- Recommendation systems in e-commerce\n",
            "- Fraud detection in banking\n",
            "- Autonomous vehicles in transportation\n",
            "\n",
            "5. Some potential challenges and ethical considerations in machine learning include:\n",
            "- Bias in data leading to biased algorithms\n",
            "- Privacy concerns with the use of personal data\n",
            "- Lack of transparency in how algorithms make decisions\n",
            "- Potential job displacement due to automation\n",
            "\n",
            "Overall, machine learning has the potential to revolutionize industries and improve efficiency, but it is important to address these challenges and ethical considerations to ensure its responsible and ethical use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ibd3whH_v1i-"
      },
      "id": "ibd3whH_v1i-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}